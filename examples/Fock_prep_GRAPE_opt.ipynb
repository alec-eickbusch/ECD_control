{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ[\"TF_GPU_ALLOCATOR\"]=\"cuda_malloc_async\" # this seems to be highly important for totally utilizing your GPU's memory, but it also breaks the profiler's memory breakdown\n",
    "# note that GradientTape needs several times the memory needed to compute the fidelity of a single circuit\n",
    "\n",
    "# the code below configures memory growth mode, so that we can more easily see how much VRAM our model needs\n",
    "# one doesn't need to run this cell to run the optimization\n",
    "\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import numpy as np\n",
    "import qutip as qt\n",
    "from ECD_control.ECD_optimization.tf_adam_optimizer import AdamOptimizer\n",
    "from ECD_control.gate_sets.GRAPE import GRAPE\n",
    "from ECD_control.ECD_optimization.GateSynthesizer import GateSynthesizer\n",
    "from ECD_control.ECD_optimization.optimization_analysis import OptimizationAnalysis, OptimizationSweepsAnalysis\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_dim = 4\n",
    "c_dim = 20\n",
    "DAC_time_resolution = 2\n",
    "fock = 4\n",
    "\n",
    "# In GHz = cycles / ns\n",
    "anharm = .4\n",
    "kerr = 1e-5\n",
    "chi = 2e-3\n",
    "drive = D = 2 * np.pi * 1e-3\n",
    "\n",
    "a = qt.tensor(qt.destroy(c_dim), qt.qeye(q_dim))\n",
    "b = qt.tensor(qt.qeye(c_dim), qt.destroy(q_dim))\n",
    "ad = a.dag()\n",
    "bd = b.dag()\n",
    "H0 = (anharm/2) * bd * bd * b * b\n",
    "H0 += (kerr/2) * ad * ad * a * a\n",
    "H0 += (chi) * ad * a * bd * b\n",
    "H0 *= 2*np.pi\n",
    "Hcs = [D*(b + bd), 1j*D*(b - bd), D*(a + ad), 1j*D*(a - ad)]\n",
    "\n",
    "init_states = [\n",
    "    qt.tensor(qt.basis(c_dim, 0), qt.basis(q_dim, 0))\n",
    "]\n",
    "\n",
    "final_states = [\n",
    "    qt.tensor(qt.basis(c_dim, fock), qt.basis(q_dim, 0))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We initialize the gateset here\n",
    "gate_set_params = {\n",
    "    'H_static' : H0,\n",
    "    'H_control' : Hcs,\n",
    "    'DAC_delta_t' : DAC_time_resolution,\n",
    "    'pulse_delta_t' : DAC_time_resolution,\n",
    "    'inplace' : True, # true uses less memory, but is slower\n",
    "    'scale' : 1.0 # range of DAC amplitudes for initial random waves\n",
    "}\n",
    "GRAPE_gate_set = GRAPE(**gate_set_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the optimization options\n",
    "synth_params = {\n",
    "    'gateset' : GRAPE_gate_set,\n",
    "    'N_blocks': 300, # note that the length of the pulse is this times the DAC_time_resolution\n",
    "    'N_multistart' : 10, #Batch size (number of circuit optimizations to run in parallel)\n",
    "    'epochs' : 3, #number of epochs before termination\n",
    "    'epoch_size' : 5, #number of adam steps per epoch\n",
    "    'learning_rate' : 0.01, #adam learning rate\n",
    "    'term_fid' : 0.995, #terminal fidelitiy\n",
    "    'dfid_stop' : 1e-6, #stop if dfid between two epochs is smaller than this number\n",
    "    'initial_states' : init_states, #qubit tensor oscillator, start in |g> |0>\n",
    "    'target_states' : final_states, #end in |e> |target>.\n",
    "    'name' : 'GRAPE Fock %d' % fock, #name for printing and saving\n",
    "    'filename' : None, #if no filename specified, results will be saved in this folder under 'name.h5'\n",
    "}\n",
    "gatesynth = GateSynthesizer(**synth_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create optimization object. \n",
    "#initial params will be randomized upon creation\n",
    "opt = AdamOptimizer(gatesynth)\n",
    "\n",
    "#print optimization info. this lives in gatesynth, since we eventually want to fully abstract away the optimizer\n",
    "gatesynth.best_fidelity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run optimizer.\n",
    "#note the optimizer can be stopped at any time by interrupting the python consle,\n",
    "#and the optimization results will still be saved and part of the opt object.\n",
    "#This allows you to stop the optimization whenever you want and still use the result.\n",
    "# Note that you will not want to use the performance profiler while using 'inplace' mode. You will run out of memory\n",
    "opt.optimize(logdir='logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension.\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch TensorBoard and navigate to the Profile tab to view performance profile\n",
    "%tensorboard --logdir=logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3e13ed3432761fc59a4a9b457fbf3f96074750791754ae943b7a2ec348e7309f"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
